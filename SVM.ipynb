{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SeokCWGxdW_",
        "outputId": "a3023603-9118-4dcd-9584-a0d6025192e8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "%cd '/content/drive/MyDrive/Project_682'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/Project_682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU2YT9f8xhls"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from glob import glob\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Cleaning Metadata"
      ],
      "metadata": {
        "id": "Ddi4_ZIGaEW4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sheQiGYAx0EU"
      },
      "source": [
        "df = pd.read_csv('HAM10000_metadata.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "lDvMKj9tho-2",
        "outputId": "bec9981b-ca13-4ab1-a014-2263b456c8ae"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10010</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033084</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10011</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033550</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10012</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033536</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10013</th>\n",
              "      <td>HAM_0000239</td>\n",
              "      <td>ISIC_0032854</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>face</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10014</th>\n",
              "      <td>HAM_0003521</td>\n",
              "      <td>ISIC_0032258</td>\n",
              "      <td>mel</td>\n",
              "      <td>histo</td>\n",
              "      <td>70.0</td>\n",
              "      <td>female</td>\n",
              "      <td>back</td>\n",
              "      <td>vidir_modern</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10015 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         lesion_id      image_id     dx  ...     sex  localization       dataset\n",
              "0      HAM_0000118  ISIC_0027419    bkl  ...    male         scalp  vidir_modern\n",
              "1      HAM_0000118  ISIC_0025030    bkl  ...    male         scalp  vidir_modern\n",
              "2      HAM_0002730  ISIC_0026769    bkl  ...    male         scalp  vidir_modern\n",
              "3      HAM_0002730  ISIC_0025661    bkl  ...    male         scalp  vidir_modern\n",
              "4      HAM_0001466  ISIC_0031633    bkl  ...    male           ear  vidir_modern\n",
              "...            ...           ...    ...  ...     ...           ...           ...\n",
              "10010  HAM_0002867  ISIC_0033084  akiec  ...    male       abdomen  vidir_modern\n",
              "10011  HAM_0002867  ISIC_0033550  akiec  ...    male       abdomen  vidir_modern\n",
              "10012  HAM_0002867  ISIC_0033536  akiec  ...    male       abdomen  vidir_modern\n",
              "10013  HAM_0000239  ISIC_0032854  akiec  ...    male          face  vidir_modern\n",
              "10014  HAM_0003521  ISIC_0032258    mel  ...  female          back  vidir_modern\n",
              "\n",
              "[10015 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM5WGKiJhrFg",
        "outputId": "09d0b7db-689c-4077-b0e1-c59d085a9601"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10015, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMdvisjuhwA1",
        "outputId": "865dcfdc-4d88-499a-9239-1dc4d8d9a28c"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lesion_id        object\n",
              "image_id         object\n",
              "dx               object\n",
              "dx_type          object\n",
              "age             float64\n",
              "sex              object\n",
              "localization     object\n",
              "dataset          object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "HdSh1Kamhyqj",
        "outputId": "ba0b9f94-e179-4e1d-8c39-419be7ca1323"
      },
      "source": [
        "df.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10015</td>\n",
              "      <td>10015</td>\n",
              "      <td>10015</td>\n",
              "      <td>10015</td>\n",
              "      <td>9958.000000</td>\n",
              "      <td>10015</td>\n",
              "      <td>10015</td>\n",
              "      <td>10015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>7470</td>\n",
              "      <td>10015</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>HAM_0003789</td>\n",
              "      <td>ISIC_0034231</td>\n",
              "      <td>nv</td>\n",
              "      <td>histo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "      <td>back</td>\n",
              "      <td>vidir_molemax</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6705</td>\n",
              "      <td>5340</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5406</td>\n",
              "      <td>2192</td>\n",
              "      <td>3954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.863828</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.968614</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          lesion_id      image_id     dx  ...    sex  localization        dataset\n",
              "count         10015         10015  10015  ...  10015         10015          10015\n",
              "unique         7470         10015      7  ...      3            15              4\n",
              "top     HAM_0003789  ISIC_0034231     nv  ...   male          back  vidir_molemax\n",
              "freq              6             1   6705  ...   5406          2192           3954\n",
              "mean            NaN           NaN    NaN  ...    NaN           NaN            NaN\n",
              "std             NaN           NaN    NaN  ...    NaN           NaN            NaN\n",
              "min             NaN           NaN    NaN  ...    NaN           NaN            NaN\n",
              "25%             NaN           NaN    NaN  ...    NaN           NaN            NaN\n",
              "50%             NaN           NaN    NaN  ...    NaN           NaN            NaN\n",
              "75%             NaN           NaN    NaN  ...    NaN           NaN            NaN\n",
              "max             NaN           NaN    NaN  ...    NaN           NaN            NaN\n",
              "\n",
              "[11 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCINirU9h1-y",
        "outputId": "9c50e46e-faf3-40dc-9272-e3c372a0b87e"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10015 entries, 0 to 10014\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   lesion_id     10015 non-null  object \n",
            " 1   image_id      10015 non-null  object \n",
            " 2   dx            10015 non-null  object \n",
            " 3   dx_type       10015 non-null  object \n",
            " 4   age           9958 non-null   float64\n",
            " 5   sex           10015 non-null  object \n",
            " 6   localization  10015 non-null  object \n",
            " 7   dataset       10015 non-null  object \n",
            "dtypes: float64(1), object(7)\n",
            "memory usage: 626.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9j8XqM1h2Cd",
        "outputId": "262cad99-89fc-4865-9857-3b51d3720437"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lesion_id        0\n",
              "image_id         0\n",
              "dx               0\n",
              "dx_type          0\n",
              "age             57\n",
              "sex              0\n",
              "localization     0\n",
              "dataset          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOxfVEhAh2Fs"
      },
      "source": [
        "mean = int(df['age'].mean())\n",
        "df['age'].fillna(mean,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_j5J7npx-or",
        "outputId": "d410eb35-c656-432b-f1fc-b1d57d405eba"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lesion_id       0\n",
              "image_id        0\n",
              "dx              0\n",
              "dx_type         0\n",
              "age             0\n",
              "sex             0\n",
              "localization    0\n",
              "dataset         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44qgv_l7yAGF"
      },
      "source": [
        "lesion_type = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}\n",
        "\n",
        "df['lesion_type'] = df['dx'].map(lesion_type.get) \n",
        "df['lesion_type_idx'] = pd.Categorical(df['lesion_type']).codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ZwxUxAiM1k"
      },
      "source": [
        "#Now time to read images based on image ID from the CSV file\n",
        "#This is the safest way to read images as it ensures the right image is read for the right ID\n",
        "imageid_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
        "                     for x in glob(os.path.join('', '*', '*.jpg'))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbEz0MaYyddN"
      },
      "source": [
        "df['path'] = df['image_id'].map(imageid_path.get)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "UEgsPiFojnB_",
        "outputId": "efaf4e40-52f0-406c-9dae-c3051e209724"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>dataset</th>\n",
              "      <th>lesion_type</th>\n",
              "      <th>lesion_type_idx</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "      <td>HAM10000/ISIC_0027419.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "      <td>HAM10000/ISIC_0025030.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "      <td>HAM10000/ISIC_0026769.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>vidir_modern</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "      <td>HAM10000/ISIC_0025661.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>vidir_modern</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "      <td>HAM10000/ISIC_0031633.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10010</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033084</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>vidir_modern</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "      <td>0</td>\n",
              "      <td>HAM10000/ISIC_0033084.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10011</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033550</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>vidir_modern</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "      <td>0</td>\n",
              "      <td>HAM10000/ISIC_0033550.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10012</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033536</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>vidir_modern</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "      <td>0</td>\n",
              "      <td>HAM10000/ISIC_0033536.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10013</th>\n",
              "      <td>HAM_0000239</td>\n",
              "      <td>ISIC_0032854</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>face</td>\n",
              "      <td>vidir_modern</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "      <td>0</td>\n",
              "      <td>HAM10000/ISIC_0032854.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10014</th>\n",
              "      <td>HAM_0003521</td>\n",
              "      <td>ISIC_0032258</td>\n",
              "      <td>mel</td>\n",
              "      <td>histo</td>\n",
              "      <td>70.0</td>\n",
              "      <td>female</td>\n",
              "      <td>back</td>\n",
              "      <td>vidir_modern</td>\n",
              "      <td>Melanoma</td>\n",
              "      <td>5</td>\n",
              "      <td>HAM10000/ISIC_0032258.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10015 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         lesion_id      image_id  ... lesion_type_idx                       path\n",
              "0      HAM_0000118  ISIC_0027419  ...               2  HAM10000/ISIC_0027419.jpg\n",
              "1      HAM_0000118  ISIC_0025030  ...               2  HAM10000/ISIC_0025030.jpg\n",
              "2      HAM_0002730  ISIC_0026769  ...               2  HAM10000/ISIC_0026769.jpg\n",
              "3      HAM_0002730  ISIC_0025661  ...               2  HAM10000/ISIC_0025661.jpg\n",
              "4      HAM_0001466  ISIC_0031633  ...               2  HAM10000/ISIC_0031633.jpg\n",
              "...            ...           ...  ...             ...                        ...\n",
              "10010  HAM_0002867  ISIC_0033084  ...               0  HAM10000/ISIC_0033084.jpg\n",
              "10011  HAM_0002867  ISIC_0033550  ...               0  HAM10000/ISIC_0033550.jpg\n",
              "10012  HAM_0002867  ISIC_0033536  ...               0  HAM10000/ISIC_0033536.jpg\n",
              "10013  HAM_0000239  ISIC_0032854  ...               0  HAM10000/ISIC_0032854.jpg\n",
              "10014  HAM_0003521  ISIC_0032258  ...               5  HAM10000/ISIC_0032258.jpg\n",
              "\n",
              "[10015 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPhnVXerjlS-",
        "outputId": "0d11e8d6-c6d5-4f87-db8d-a418b305d5a8"
      },
      "source": [
        "df['lesion_type_idx'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    6705\n",
              "5    1113\n",
              "2    1099\n",
              "1     514\n",
              "0     327\n",
              "6     142\n",
              "3     115\n",
              "Name: lesion_type_idx, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Denoise, Resize and Data Augmentation"
      ],
      "metadata": {
        "id": "qgQ7I8lvZ3TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from cv2 import imread, resize"
      ],
      "metadata": {
        "id": "kFOaDdLKaNXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwJIuvmTjOk2"
      },
      "source": [
        "def produce_new_img(img2):\n",
        "    imga = cv2.rotate(img2,cv2.ROTATE_90_CLOCKWISE)\n",
        "    imgb = cv2.rotate(img2,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "    imgc = cv2.rotate(img2,cv2.ROTATE_180)\n",
        "    imgd = cv2.flip(img2,0)\n",
        "    imge = cv2.flip(img2,1)\n",
        "    return imga,imgb,imgc,imgd,imge\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "kernel = cv2.getStructuringElement(1,(17,17)) # Kernel for the morphological filtering\n",
        "\n",
        "for i in range(len(df)):\n",
        "  src = cv2.imread(df['path'][i])\n",
        "  grayScale = cv2.cvtColor( src, cv2.COLOR_RGB2GRAY ) #1 Convert the original image to grayscale\n",
        "  blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel) #2 Perform the blackHat filtering on the grayscale image to find the hair countours\n",
        "  ret,thresh2 = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY) # intensify the hair countours in preparation for the inpainting algorithm\n",
        "  dst = cv2.inpaint(src,thresh2,1,cv2.INPAINT_TELEA) # inpaint the original image depending on the mask\n",
        "\n",
        "  file_to_read = df['path'][i]\n",
        "  img = imread(file_to_read)\n",
        "  img2 = resize(dst,(50,50))\n",
        "  X.append(img2)\n",
        "    \n",
        "  #targets\n",
        "  output = df['lesion_type_idx'][i]\n",
        "  y.append(output)\n",
        "    \n",
        "  # add more images for class between 1-6, rotating them \n",
        "  if output != 4:\n",
        "    new_img = produce_new_img(img2)\n",
        "    for i in range(5):\n",
        "      X.append(new_img[i])\n",
        "      y.append(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqd4Z6RBMfw5",
        "outputId": "fda850de-eba7-470a-ba17-d1511aa077f5"
      },
      "source": [
        "print(y.count(0),y.count(1),y.count(2),y.count(3),y.count(4),y.count(5),y.count(6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1962 3084 6594 690 6705 6678 852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving data after pre-processing"
      ],
      "metadata": {
        "id": "nsATAd3Acn0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "LYkMCHugcoFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"X.pkl\"\n",
        "\n",
        "#open_file = open(file_name, \"wb\")\n",
        "#pickle.dump(X, open_file)\n",
        "#open_file.close()\n",
        "\n",
        "open_file = open(file_name, \"rb\")\n",
        "X = pickle.load(open_file)\n",
        "open_file.close()\n",
        "\n",
        "#print(X)"
      ],
      "metadata": {
        "id": "ju5nTDkScoIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= np.array(X)"
      ],
      "metadata": {
        "id": "SMWWiKy5coMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "nw4qMtUQcoPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.astype(np.float64)"
      ],
      "metadata": {
        "id": "93gF_wCacoS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.dtype"
      ],
      "metadata": {
        "id": "eaivVjZWcogI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"y.pkl\"\n",
        "\n",
        "#open_file = open(file_name, \"wb\")\n",
        "#pickle.dump(y, open_file)\n",
        "#open_file.close()\n",
        "\n",
        "open_file = open(file_name, \"rb\")\n",
        "y = pickle.load(open_file)\n",
        "open_file.close()\n",
        "\n",
        "#print(y)"
      ],
      "metadata": {
        "id": "BDbhZ_fwdAB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "esa55q3VdI6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "6t5HJx2hdAFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA48daGmL5I5"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "#y_train = to_categorical(y, num_classes=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFiDpjaTA3lL"
      },
      "source": [
        "X = X.astype(np.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyvqes2gsf4m"
      },
      "source": [
        "#y_train = [1 if each == 5 else 0 for each in y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test split"
      ],
      "metadata": {
        "id": "BtfmofKfaSwU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0tQBoWiL8iQ",
        "outputId": "eb4ae7ad-bef3-438d-cf1d-33225a0b05f7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split in 70% training and 30% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
        "\n",
        "\n",
        "print('Train dataset shape',X_train.shape)\n",
        "print('Test dataset shape',X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape (21252, 50, 50, 3)\n",
            "Test dataset shape (5313, 50, 50, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r98VnFZumEto"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biueoBnxmpJw"
      },
      "source": [
        "# This is a bit of magic to make matplotlib figures appear inline in the\n",
        "# notebook rather than in a new window.\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# Some more magic so that the notebook will reload external python modules;\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I74GxXAkj4xW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1306351e-6afb-40e2-8190-fd2fa7b8d9be"
      },
      "source": [
        "# Split the data into train, val, and test sets. In addition we will\n",
        "# create a small development set as a subset of the training data;\n",
        "# we can use this for development so our code runs faster.\n",
        "num_training = 20000\n",
        "num_validation = 1252\n",
        "num_test = 5313\n",
        "num_dev = 252\n",
        "\n",
        "# Our validation set will be num_validation points from the original\n",
        "# training set.\n",
        "mask = range(num_training, num_training + num_validation)\n",
        "X_val = X_train[mask]\n",
        "y_val = y_train[mask]\n",
        "\n",
        "# Our training set will be the first num_train points from the original\n",
        "# training set.\n",
        "mask = range(num_training)\n",
        "X_train = X_train[mask]\n",
        "y_train = y_train[mask]\n",
        "\n",
        "# We will also make a development set, which is a small subset of\n",
        "# the training set.\n",
        "mask = np.random.choice(num_training, num_dev, replace=False)\n",
        "X_dev = X_train[mask]\n",
        "y_dev = y_train[mask]\n",
        "\n",
        "# We use the first num_test points of the original test set as our\n",
        "# test set.\n",
        "mask = range(num_test)\n",
        "X_test = X_test[mask]\n",
        "y_test = y_test[mask]\n",
        "\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape:  (20000, 50, 50, 3)\n",
            "Train labels shape:  (20000,)\n",
            "Validation data shape:  (1252, 50, 50, 3)\n",
            "Validation labels shape:  (1252,)\n",
            "Test data shape:  (5313, 50, 50, 3)\n",
            "Test labels shape:  (5313,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2-xYAqgj40K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0f0b83-627b-45c8-b5f5-07ac9168b7c3"
      },
      "source": [
        "# Preprocessing: reshape the image data into rows\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
        "\n",
        "# As a sanity check, print out the shapes of the data\n",
        "print('Training data shape: ', X_train.shape)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('dev data shape: ', X_dev.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape:  (20000, 7500)\n",
            "Validation data shape:  (1252, 7500)\n",
            "Test data shape:  (5313, 7500)\n",
            "dev data shape:  (252, 7500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXhqAuMuj42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "a9685a55-e613-4f62-8b66-5ee551c0e3b8"
      },
      "source": [
        "# Preprocessing: subtract the mean image\n",
        "# first: compute the image mean based on the training data\n",
        "mean_image = np.mean(X_train, axis=0)\n",
        "print(mean_image[:10]) # print a few of the elements\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(mean_image.reshape((50,50,3)).astype('uint8')) # visualize the mean image\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[130.5766  122.6324  160.91665 134.3819  126.2479  165.0601  137.9716\n",
            " 129.64785 168.9681  141.50885]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPyw4H0tj44s"
      },
      "source": [
        "# second: subtract the mean image from train and test data\n",
        "X_train = X_train -  mean_image\n",
        "X_val = X_val -  mean_image\n",
        "X_test = X_test - mean_image\n",
        "X_dev = X_dev - mean_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ5MBvtWj49h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01465f4f-b589-4cd8-aaf1-7c7ba586df5c"
      },
      "source": [
        "# third: append the bias dimension of ones (i.e. bias trick) so that our SVM\n",
        "# only has to worry about optimizing a single weight matrix W.\n",
        "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
        "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
        "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
        "X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 7501) (1252, 7501) (5313, 7501) (252, 7501)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHNHSNuXj4_-"
      },
      "source": [
        "import numpy as np\n",
        "from random import shuffle\n",
        "\n",
        "def svm_loss_naive(W, X, y, reg):\n",
        "  \"\"\"\n",
        "  Structured SVM loss function, naive implementation (with loops).\n",
        "\n",
        "  Inputs have dimension D, there are C classes, and we operate on minibatches\n",
        "  of N examples.\n",
        "\n",
        "  Inputs:\n",
        "  - W: A numpy array of shape (D, C) containing weights.\n",
        "  - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
        "  - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
        "    that X[i] has label c, where 0 <= c < C.\n",
        "  - reg: (float) regularization strength\n",
        "\n",
        "  Returns a tuple of:\n",
        "  - loss as single float\n",
        "  - gradient with respect to weights W; an array of same shape as W\n",
        "  \"\"\"\n",
        "  dW = np.zeros(W.shape) # initialize the gradient as zero\n",
        "\n",
        "  # compute the loss and the gradient\n",
        "  num_classes = W.shape[1]\n",
        "  num_train = X.shape[0]\n",
        "  loss = 0.0\n",
        "  for i in range(num_train):\n",
        "    scores = X[i].dot(W)\n",
        "    correct_class_score = scores[y[i]]\n",
        "    for j in range(num_classes):\n",
        "      if j == y[i]:\n",
        "        continue\n",
        "      margin = scores[j] - correct_class_score + 1 # note delta = 1\n",
        "      if margin > 0:\n",
        "        dW[:,j] = dW[:,j] + X[i]\n",
        "        dW[:,y[i]] = dW[:,y[i]] -X[i]\n",
        "        loss += margin\n",
        "\n",
        "  # Right now the loss is a sum over all training examples, but we want it\n",
        "  # to be an average instead so we divide by num_train.\n",
        "  loss /= num_train\n",
        "  dW /= num_train\n",
        "\n",
        "  # Add regularization to the loss.\n",
        "  loss += reg * np.sum(W * W)\n",
        "  dW += reg * 2 * W\n",
        "\n",
        "  #############################################################################\n",
        "  # TODO:                                                                     #\n",
        "  # Compute the gradient of the loss function and store it dW.                #\n",
        "  # Rather that first computing the loss and then computing the derivative,   #\n",
        "  # it may be simpler to compute the derivative at the same time that the     #\n",
        "  # loss is being computed. As a result you may need to modify some of the    #\n",
        "  # code above to compute the gradient.                                       #\n",
        "  #############################################################################\n",
        "\n",
        "\n",
        "  return loss, dW\n",
        "\n",
        "\n",
        "def svm_loss_vectorized(W, X, y, reg):\n",
        "  \"\"\"\n",
        "  Structured SVM loss function, vectorized implementation.\n",
        "\n",
        "  Inputs and outputs are the same as svm_loss_naive.\n",
        "  \"\"\"\n",
        "  loss = 0.0\n",
        "  dW = np.zeros(W.shape) # initialize the gradient as zero\n",
        "\n",
        "  #############################################################################\n",
        "  # TODO:                                                                     #\n",
        "  # Implement a vectorized version of the structured SVM loss, storing the    #\n",
        "  # result in loss.                                                           #\n",
        "  #############################################################################\n",
        "  num_train = X.shape[0]\n",
        "\n",
        "  scores = X.dot(W)\n",
        "  #print(scores.shape)\n",
        "  correct_class_score_y = scores[np.arange(num_train), y]\n",
        "  #print(correct_class_score_y.shape)\n",
        "  l = scores - correct_class_score_y[:,None] + 1\n",
        "  #print(l.shape)\n",
        "  #print(l)\n",
        "  l[np.arange(num_train), y] -=1\n",
        "  l_max = np.maximum(0, l)\n",
        "  #print(l_max.shape)\n",
        "  #print(l_max)\n",
        "  Final_l = np.sum(l_max)\n",
        "\n",
        "  loss = (Final_l/num_train)\n",
        "  #print(loss)\n",
        "\n",
        "  # Add regularization to the loss.\n",
        "  loss += reg * np.sum(W * W) \n",
        "\n",
        "  pass\n",
        "  #############################################################################\n",
        "  #                             END OF YOUR CODE                              #\n",
        "  #############################################################################\n",
        "\n",
        "\n",
        "  #############################################################################\n",
        "  # TODO:                                                                     #\n",
        "  # Implement a vectorized version of the gradient for the structured SVM     #\n",
        "  # loss, storing the result in dW.                                           #\n",
        "  #                                                                           #\n",
        "  # Hint: Instead of computing the gradient from scratch, it may be easier    #\n",
        "  # to reuse some of the intermediate values that you used to compute the     #\n",
        "  # loss.                                                                     #\n",
        "  #############################################################################\n",
        "\n",
        "  mask = np.zeros(l_max.shape)\n",
        "  #print(mask.shape)\n",
        "  case = l_max>0\n",
        "  mask[case] = 1\n",
        "  mask_sum = np.sum(mask, axis=1)\n",
        "  #print(mask_sum.shape)\n",
        "  mask[np.arange(num_train), y] = -mask_sum\n",
        "  #print(mask.shape)\n",
        "  dW = np.dot(X.T, mask)\n",
        "\n",
        "  # Average\n",
        "  dW /= num_train\n",
        "\n",
        "  # Regularize\n",
        "  dW += reg * 2 * W\n",
        "  pass\n",
        "  #############################################################################\n",
        "  #                             END OF YOUR CODE                              #\n",
        "  #############################################################################\n",
        "\n",
        "  return loss, dW\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ0ksbHiTPzD"
      },
      "source": [
        "import numpy as np\n",
        "from random import shuffle\n",
        "\n",
        "def softmax_loss_naive(W, X, y, reg):\n",
        "  \"\"\"\n",
        "  Softmax loss function, naive implementation (with loops)\n",
        "\n",
        "  Inputs have dimension D, there are C classes, and we operate on minibatches\n",
        "  of N examples.\n",
        "\n",
        "  Inputs:\n",
        "  - W: A numpy array of shape (D, C) containing weights.\n",
        "  - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
        "  - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
        "    that X[i] has label c, where 0 <= c < C.\n",
        "  - reg: (float) regularization strength\n",
        "\n",
        "  Returns a tuple of:\n",
        "  - loss as single float\n",
        "  - gradient with respect to weights W; an array of same shape as W\n",
        "  \"\"\"\n",
        "  # Initialize the loss and gradient to zero.\n",
        "  loss = 0.0\n",
        "  dW = np.zeros_like(W)\n",
        "\n",
        "  #############################################################################\n",
        "  # TODO: Compute the softmax loss and its gradient using explicit loops.     #\n",
        "  # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "  # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "  # regularization!                                                           #\n",
        "  #############################################################################\n",
        "  # compute the loss and the gradient\n",
        "  num_classes = W.shape[1]\n",
        "  num_train = X.shape[0]\n",
        "  \n",
        "  for i in range(num_train):\n",
        "    scores = X[i].dot(W)\n",
        "    correct_class_score = scores[y[i]]\n",
        "    exp= np.exp(scores)\n",
        "    sum_exp = np.sum(exp)\n",
        "    log_sum_exp = np.log(sum_exp)\n",
        "    loss += (-correct_class_score + log_sum_exp)\n",
        "  \n",
        "    for j in range(num_classes):\n",
        "      softmax_function = np.exp(scores[j]) / sum_exp\n",
        "      if j == y[i]:\n",
        "        dW[:,j] = dW[:,j] + ((-1 + softmax_function) *X[i]) \n",
        "      else: \n",
        "        dW[:,j] = dW[:,j] + softmax_function *X[i] \n",
        "\n",
        "  # Right now the loss is a sum over all training examples, but we want it\n",
        "  # to be an average instead so we divide by num_train.\n",
        "  loss /= num_train\n",
        "  dW /= num_train\n",
        "\n",
        "  # Add regularization to the loss.\n",
        "  loss += reg * np.sum(W * W)\n",
        "  dW += reg * 2 * W\n",
        "\n",
        "  pass\n",
        "  #############################################################################\n",
        "  #                          END OF YOUR CODE                                 #\n",
        "  #############################################################################\n",
        "\n",
        "  return loss, dW\n",
        "\n",
        "\n",
        "def softmax_loss_vectorized(W, X, y, reg):\n",
        "  \"\"\"\n",
        "  Softmax loss function, vectorized version.\n",
        "\n",
        "  Inputs and outputs are the same as softmax_loss_naive.\n",
        "  \"\"\"\n",
        "  # Initialize the loss and gradient to zero.\n",
        "  loss = 0.0\n",
        "  dW = np.zeros_like(W)\n",
        "\n",
        "  #############################################################################\n",
        "  # TODO: Compute the softmax loss and its gradient using no explicit loops.  #\n",
        "  # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "  # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "  # regularization!                                                           #\n",
        "  #############################################################################\n",
        "  num_train = X.shape[0]\n",
        "  scores = X.dot(W)\n",
        "  #print(scores.shape)\n",
        "  correct_class_score_y = scores[np.arange(num_train), y]\n",
        "  #print(correct_class_score_y.shape)\n",
        "  sum_correct_class_score_y = np.sum(-correct_class_score_y)\n",
        "  #print(sum_correct_class_score_y)\n",
        "  exp= np.exp(scores)\n",
        "  sum_exp = np.sum(exp, axis=1)\n",
        "  log_sum_exp = np.log(sum_exp)\n",
        "  Final_l = sum_correct_class_score_y + np.sum(log_sum_exp)\n",
        "\n",
        "  #Gradient\n",
        "  #print(exp.shape)\n",
        "  #print(sum_exp.shape)\n",
        "  Grad = exp / sum_exp[:,None]\n",
        "  #print(Grad.shape)\n",
        "  Grad[np.arange(num_train),y] -=1\n",
        "  dW = X.T.dot(Grad)\n",
        "\n",
        "  loss = (Final_l/num_train)\n",
        "  dW /= num_train\n",
        "  #print(loss)\n",
        "\n",
        "  # Add regularization to the loss.\n",
        "  loss += reg * np.sum(W * W)\n",
        "  dW += reg * 2 * W\n",
        "  pass\n",
        "  #############################################################################\n",
        "  #                          END OF YOUR CODE                                 #\n",
        "  #############################################################################\n",
        "\n",
        "  return loss, dW\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_wsJ1k2TMpV"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class LinearClassifier(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.W = None\n",
        "\n",
        "  def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
        "            batch_size=200, verbose=False):\n",
        "    \"\"\"\n",
        "    Train this linear classifier using stochastic gradient descent.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
        "      training samples each of dimension D.\n",
        "    - y: A numpy array of shape (N,) containing training labels; y[i] = c\n",
        "      means that X[i] has label 0 <= c < C for C classes.\n",
        "    - learning_rate: (float) learning rate for optimization.\n",
        "    - reg: (float) regularization strength.\n",
        "    - num_iters: (integer) number of steps to take when optimizing\n",
        "    - batch_size: (integer) number of training examples to use at each step.\n",
        "    - verbose: (boolean) If true, print progress during optimization.\n",
        "\n",
        "    Outputs:\n",
        "    A list containing the value of the loss function at each training iteration.\n",
        "    \"\"\"\n",
        "    num_train, dim = X.shape\n",
        "    num_classes = np.max(y) + 1 # assume y takes values 0...K-1 where K is number of classes\n",
        "    if self.W is None:\n",
        "      # lazily initialize W\n",
        "      self.W = 0.001 * np.random.randn(dim, num_classes)\n",
        "\n",
        "    # Run stochastic gradient descent to optimize W\n",
        "    loss_history = []\n",
        "    for it in range(num_iters):\n",
        "      X_batch = None\n",
        "      y_batch = None\n",
        "\n",
        "      #########################################################################\n",
        "      # TODO:                                                                 #\n",
        "      # Sample batch_size elements from the training data and their           #\n",
        "      # corresponding labels to use in this round of gradient descent.        #\n",
        "      # Store the data in X_batch and their corresponding labels in           #\n",
        "      # y_batch; after sampling X_batch should have shape (dim, batch_size)   #\n",
        "      # and y_batch should have shape (batch_size,)                           #\n",
        "      #                                                                       #\n",
        "      # Hint: Use np.random.choice to generate indices. Sampling with         #\n",
        "      # replacement is faster than sampling without replacement.              #\n",
        "      #########################################################################\n",
        "      sampling_indices = np.random.choice(num_train,batch_size)\n",
        "      #print(sampling_indices.shape)\n",
        "      X_batch = X[sampling_indices]\n",
        "      #print(X_batch.shape)\n",
        "      y_batch = y[sampling_indices]\n",
        "      #print(y_batch.shape)\n",
        "      pass\n",
        "      #########################################################################\n",
        "      #                       END OF YOUR CODE                                #\n",
        "      #########################################################################\n",
        "\n",
        "      # evaluate loss and gradient\n",
        "      loss, grad = self.loss(X_batch, y_batch, reg)\n",
        "      loss_history.append(loss)\n",
        "\n",
        "      # perform parameter update\n",
        "      #########################################################################\n",
        "      # TODO:                                                                 #\n",
        "      # Update the weights using the gradient and the learning rate.          #\n",
        "      #########################################################################\n",
        "      self.W = self.W - learning_rate * grad\n",
        "      pass\n",
        "      #########################################################################\n",
        "      #                       END OF YOUR CODE                                #\n",
        "      #########################################################################\n",
        "\n",
        "      if verbose and it % 100 == 0:\n",
        "        print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Use the trained weights of this linear classifier to predict labels for\n",
        "    data points.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
        "      training samples each of dimension D.\n",
        "\n",
        "    Returns:\n",
        "    - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
        "      array of length N, and each element is an integer giving the predicted\n",
        "      class.\n",
        "    \"\"\"\n",
        "    y_pred = np.zeros(X.shape[0])\n",
        "    ###########################################################################\n",
        "    # TODO:                                                                   #\n",
        "    # Implement this method. Store the predicted labels in y_pred.            #\n",
        "    ###########################################################################\n",
        "    #print(y_pred.shape)\n",
        "    #print(self.W.shape)\n",
        "    scores = X.dot(self.W)\n",
        "    #print(scores.shape) \n",
        "    max_scores = np.argmax(scores, axis=1)\n",
        "    #print(max_scores.shape)\n",
        "    y_pred = max_scores\n",
        "    pass\n",
        "    ###########################################################################\n",
        "    #                           END OF YOUR CODE                              #\n",
        "    ###########################################################################\n",
        "    return y_pred\n",
        "\n",
        "  def loss(self, X_batch, y_batch, reg):\n",
        "    \"\"\"\n",
        "    Compute the loss function and its derivative.\n",
        "    Subclasses will override this.\n",
        "\n",
        "    Inputs:\n",
        "    - X_batch: A numpy array of shape (N, D) containing a minibatch of N\n",
        "      data points; each point has dimension D.\n",
        "    - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "    - reg: (float) regularization strength.\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to self.W; an array of the same shape as W\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class LinearSVM(LinearClassifier):\n",
        "  \"\"\" A subclass that uses the Multiclass SVM loss function \"\"\"\n",
        "\n",
        "  def loss(self, X_batch, y_batch, reg):\n",
        "    return svm_loss_vectorized(self.W, X_batch, y_batch, reg)\n",
        "    #return svm_loss_naive(self.W, X_batch, y_batch, reg)\n",
        "\n",
        "\n",
        "class Softmax(LinearClassifier):\n",
        "  \"\"\" A subclass that uses the Softmax + Cross-entropy loss function \"\"\"\n",
        "\n",
        "  def loss(self, X_batch, y_batch, reg):\n",
        "    return softmax_loss_vectorized(self.W, X_batch, y_batch, reg)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tlukCbUj5Cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda564e0-62d5-49c9-aa8c-8caefa3fbece"
      },
      "source": [
        "import time\n",
        "\n",
        "# generate a random SVM weight matrix of small numbers\n",
        "W = np.random.randn(7501, 7) * 0.0001 \n",
        "\n",
        "loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.000005)\n",
        "print('loss: %f' % (loss, ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 5.732113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ar6YcIvj5FU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe72abf4-5be7-482b-ab03-e5d764cf7b7c"
      },
      "source": [
        "# In the file linear_classifier.py, implement SGD in the function\n",
        "# LinearClassifier.train() and then run it with the code below.\n",
        "svm = LinearSVM()\n",
        "tic = time.time()\n",
        "loss_hist = svm.train(X_train, y_train, learning_rate=1e-7, reg=2.5e4,\n",
        "                      num_iters=1500, verbose=True)\n",
        "toc = time.time()\n",
        "print('That took %fs' % (toc - tic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0 / 1500: loss 1335.602757\n",
            "iteration 100 / 1500: loss 487.811415\n",
            "iteration 200 / 1500: loss 180.974047\n",
            "iteration 300 / 1500: loss 68.114237\n",
            "iteration 400 / 1500: loss 26.901948\n",
            "iteration 500 / 1500: loss 12.164379\n",
            "iteration 600 / 1500: loss 6.939884\n",
            "iteration 700 / 1500: loss 4.731552\n",
            "iteration 800 / 1500: loss 4.065711\n",
            "iteration 900 / 1500: loss 3.644685\n",
            "iteration 1000 / 1500: loss 3.310620\n",
            "iteration 1100 / 1500: loss 3.540954\n",
            "iteration 1200 / 1500: loss 3.678685\n",
            "iteration 1300 / 1500: loss 3.445148\n",
            "iteration 1400 / 1500: loss 3.568559\n",
            "That took 23.007956s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjIFwvMvj5Hw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "1e3776ab-692b-44a3-8cd9-7e882f0f2727"
      },
      "source": [
        "# A useful debugging strategy is to plot the loss as a function of\n",
        "# iteration number:\n",
        "plt.plot(loss_hist)\n",
        "plt.xlabel('Iteration number')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swpG8JU8j5Km",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b598274-e224-41fb-ea1a-2d18193704a3"
      },
      "source": [
        "# Write the LinearSVM.predict function and evaluate the performance on both the\n",
        "# training and validation set\n",
        "y_train_pred = svm.predict(X_train)\n",
        "print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))\n",
        "y_val_pred = svm.predict(X_val)\n",
        "print('validation accuracy: %f' % (np.mean(y_val == y_val_pred), ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy: 0.493150\n",
            "validation accuracy: 0.498403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw1NanTLj5NL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d81f9b-8353-464b-ee58-cbffda4de1b1"
      },
      "source": [
        "# Use the validation set to tune hyperparameters (regularization strength and\n",
        "# learning rate). You should experiment with different ranges for the learning\n",
        "# rates and regularization strengths; if you are careful you should be able to\n",
        "# get a classification accuracy of about 0.4 on the validation set.\n",
        "learning_rates = [1e-8, 1e-7, 1e-6]\n",
        "regularization_strengths = [1e3, 2e3, 3e3, 1e4, 2e4, 3e4, 1e5]\n",
        "#learning_rates = [1e-7, 1e-6, 5e-5]\n",
        "#regularization_strengths = [1e4, 2e4, 2.3e4, 2.5e4, 3e4, 4e4, 5e4]\n",
        "\n",
        "# results is dictionary mapping tuples of the form\n",
        "# (learning_rate, regularization_strength) to tuples of the form\n",
        "# (training_accuracy, validation_accuracy). The accuracy is simply the fraction\n",
        "# of data points that are correctly classified.\n",
        "results = {}\n",
        "best_val = -1   # The highest validation accuracy that we have seen so far.\n",
        "best_svm = None # The LinearSVM object that achieved the highest validation rate.\n",
        "\n",
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Write code that chooses the best hyperparameters by tuning on the validation #\n",
        "# set. For each combination of hyperparameters, train a linear SVM on the      #\n",
        "# training set, compute its accuracy on the training and validation sets, and  #\n",
        "# store these numbers in the results dictionary. In addition, store the best   #\n",
        "# validation accuracy in best_val and the LinearSVM object that achieves this  #\n",
        "# accuracy in best_svm.                                                        #\n",
        "#                                                                              #\n",
        "# Hint: You should use a small value for num_iters as you develop your         #\n",
        "# validation code so that the SVMs don't take much time to train; once you are #\n",
        "# confident that your validation code works, you should rerun the validation   #\n",
        "# code with a larger value for num_iters.                                      #\n",
        "################################################################################\n",
        "# Your code\n",
        "for lr in learning_rates:\n",
        "  for rs in regularization_strengths: \n",
        "    svm = LinearSVM()\n",
        "    loss_hist = svm.train(X_train, y_train, learning_rate=lr, reg=rs,\n",
        "                          num_iters=2500, verbose=True)\n",
        "    y_train_pred = svm.predict(X_train)\n",
        "    training_accuracy = np.mean(y_train == y_train_pred) \n",
        "    #print('training accuracy: ', training_accuracy)\n",
        "    y_val_pred = svm.predict(X_val)\n",
        "    validation_accuracy = np.mean(y_val == y_val_pred)\n",
        "    #print('validation accuracy: ', validation_accuracy)\n",
        "\n",
        "    # Storing in results dictionary\n",
        "    results[(lr,rs)] = (training_accuracy,validation_accuracy)\n",
        "\n",
        "    if(validation_accuracy>best_val):\n",
        "      best_val = validation_accuracy\n",
        "      best_svm = svm\n",
        "      best_y_val_pred = y_val_pred\n",
        "\n",
        "################################################################################\n",
        "#                              END OF YOUR CODE                                #\n",
        "################################################################################\n",
        "    \n",
        "# Print out results.\n",
        "for lr, reg in sorted(results):\n",
        "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
        "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
        "                lr, reg, train_accuracy, val_accuracy))\n",
        "    \n",
        "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0 / 2500: loss 68.160685\n",
            "iteration 100 / 2500: loss 62.245520\n",
            "iteration 200 / 2500: loss 61.098470\n",
            "iteration 300 / 2500: loss 60.436813\n",
            "iteration 400 / 2500: loss 60.696606\n",
            "iteration 500 / 2500: loss 58.390902\n",
            "iteration 600 / 2500: loss 57.772809\n",
            "iteration 700 / 2500: loss 57.858567\n",
            "iteration 800 / 2500: loss 55.845976\n",
            "iteration 900 / 2500: loss 56.978609\n",
            "iteration 1000 / 2500: loss 55.647923\n",
            "iteration 1100 / 2500: loss 55.503221\n",
            "iteration 1200 / 2500: loss 55.426523\n",
            "iteration 1300 / 2500: loss 54.930076\n",
            "iteration 1400 / 2500: loss 55.170483\n",
            "iteration 1500 / 2500: loss 53.987507\n",
            "iteration 1600 / 2500: loss 54.328528\n",
            "iteration 1700 / 2500: loss 54.046825\n",
            "iteration 1800 / 2500: loss 53.953235\n",
            "iteration 1900 / 2500: loss 53.587913\n",
            "iteration 2000 / 2500: loss 53.544879\n",
            "iteration 2100 / 2500: loss 53.563605\n",
            "iteration 2200 / 2500: loss 52.850357\n",
            "iteration 2300 / 2500: loss 53.302781\n",
            "iteration 2400 / 2500: loss 53.105423\n",
            "iteration 0 / 2500: loss 117.044967\n",
            "iteration 100 / 2500: loss 113.422891\n",
            "iteration 200 / 2500: loss 110.660006\n",
            "iteration 300 / 2500: loss 109.399804\n",
            "iteration 400 / 2500: loss 107.700944\n",
            "iteration 500 / 2500: loss 108.886884\n",
            "iteration 600 / 2500: loss 106.293870\n",
            "iteration 700 / 2500: loss 105.289091\n",
            "iteration 800 / 2500: loss 103.798609\n",
            "iteration 900 / 2500: loss 103.699603\n",
            "iteration 1000 / 2500: loss 102.160510\n",
            "iteration 1100 / 2500: loss 101.648178\n",
            "iteration 1200 / 2500: loss 101.261273\n",
            "iteration 1300 / 2500: loss 100.111579\n",
            "iteration 1400 / 2500: loss 99.011667\n",
            "iteration 1500 / 2500: loss 98.004167\n",
            "iteration 1600 / 2500: loss 97.250973\n",
            "iteration 1700 / 2500: loss 96.606699\n",
            "iteration 1800 / 2500: loss 96.273661\n",
            "iteration 1900 / 2500: loss 94.794308\n",
            "iteration 2000 / 2500: loss 94.515335\n",
            "iteration 2100 / 2500: loss 93.502754\n",
            "iteration 2200 / 2500: loss 92.976998\n",
            "iteration 2300 / 2500: loss 92.493436\n",
            "iteration 2400 / 2500: loss 91.457511\n",
            "iteration 0 / 2500: loss 169.410827\n",
            "iteration 100 / 2500: loss 165.438873\n",
            "iteration 200 / 2500: loss 161.880798\n",
            "iteration 300 / 2500: loss 158.278453\n",
            "iteration 400 / 2500: loss 156.982149\n",
            "iteration 500 / 2500: loss 154.715729\n",
            "iteration 600 / 2500: loss 152.562357\n",
            "iteration 700 / 2500: loss 151.218227\n",
            "iteration 800 / 2500: loss 148.132910\n",
            "iteration 900 / 2500: loss 146.708700\n",
            "iteration 1000 / 2500: loss 144.663611\n",
            "iteration 1100 / 2500: loss 143.464126\n",
            "iteration 1200 / 2500: loss 141.468064\n",
            "iteration 1300 / 2500: loss 140.442382\n",
            "iteration 1400 / 2500: loss 137.266594\n",
            "iteration 1500 / 2500: loss 136.124690\n",
            "iteration 1600 / 2500: loss 134.605433\n",
            "iteration 1700 / 2500: loss 132.986242\n",
            "iteration 1800 / 2500: loss 131.654240\n",
            "iteration 1900 / 2500: loss 130.366579\n",
            "iteration 2000 / 2500: loss 128.005884\n",
            "iteration 2100 / 2500: loss 126.659406\n",
            "iteration 2200 / 2500: loss 125.873306\n",
            "iteration 2300 / 2500: loss 123.616741\n",
            "iteration 2400 / 2500: loss 122.101724\n",
            "iteration 0 / 2500: loss 536.787390\n",
            "iteration 100 / 2500: loss 511.384999\n",
            "iteration 200 / 2500: loss 491.452208\n",
            "iteration 300 / 2500: loss 472.296162\n",
            "iteration 400 / 2500: loss 453.188043\n",
            "iteration 500 / 2500: loss 435.633030\n",
            "iteration 600 / 2500: loss 419.170159\n",
            "iteration 700 / 2500: loss 402.218561\n",
            "iteration 800 / 2500: loss 385.740881\n",
            "iteration 900 / 2500: loss 370.722363\n",
            "iteration 1000 / 2500: loss 356.378345\n",
            "iteration 1100 / 2500: loss 341.798553\n",
            "iteration 1200 / 2500: loss 328.484399\n",
            "iteration 1300 / 2500: loss 316.693698\n",
            "iteration 1400 / 2500: loss 304.570634\n",
            "iteration 1500 / 2500: loss 291.607888\n",
            "iteration 1600 / 2500: loss 280.531916\n",
            "iteration 1700 / 2500: loss 270.152755\n",
            "iteration 1800 / 2500: loss 259.186248\n",
            "iteration 1900 / 2500: loss 249.007782\n",
            "iteration 2000 / 2500: loss 239.812188\n",
            "iteration 2100 / 2500: loss 230.089773\n",
            "iteration 2200 / 2500: loss 220.850039\n",
            "iteration 2300 / 2500: loss 212.956160\n",
            "iteration 2400 / 2500: loss 204.262062\n",
            "iteration 0 / 2500: loss 1072.314575\n",
            "iteration 100 / 2500: loss 987.330921\n",
            "iteration 200 / 2500: loss 908.074179\n",
            "iteration 300 / 2500: loss 837.799709\n",
            "iteration 400 / 2500: loss 773.264122\n",
            "iteration 500 / 2500: loss 713.210032\n",
            "iteration 600 / 2500: loss 658.484295\n",
            "iteration 700 / 2500: loss 607.952215\n",
            "iteration 800 / 2500: loss 561.651692\n",
            "iteration 900 / 2500: loss 518.332474\n",
            "iteration 1000 / 2500: loss 478.412851\n",
            "iteration 1100 / 2500: loss 441.356702\n",
            "iteration 1200 / 2500: loss 408.244433\n",
            "iteration 1300 / 2500: loss 376.910642\n",
            "iteration 1400 / 2500: loss 347.319057\n",
            "iteration 1500 / 2500: loss 320.984385\n",
            "iteration 1600 / 2500: loss 296.676836\n",
            "iteration 1700 / 2500: loss 274.427173\n",
            "iteration 1800 / 2500: loss 254.135651\n",
            "iteration 1900 / 2500: loss 233.882350\n",
            "iteration 2000 / 2500: loss 216.409164\n",
            "iteration 2100 / 2500: loss 200.140129\n",
            "iteration 2200 / 2500: loss 184.875522\n",
            "iteration 2300 / 2500: loss 170.865441\n",
            "iteration 2400 / 2500: loss 157.734335\n",
            "iteration 0 / 2500: loss 1583.527333\n",
            "iteration 100 / 2500: loss 1400.803765\n",
            "iteration 200 / 2500: loss 1243.004670\n",
            "iteration 300 / 2500: loss 1102.148909\n",
            "iteration 400 / 2500: loss 977.046056\n",
            "iteration 500 / 2500: loss 866.188888\n",
            "iteration 600 / 2500: loss 769.240157\n",
            "iteration 700 / 2500: loss 682.245703\n",
            "iteration 800 / 2500: loss 605.936596\n",
            "iteration 900 / 2500: loss 537.678963\n",
            "iteration 1000 / 2500: loss 476.737055\n",
            "iteration 1100 / 2500: loss 423.038512\n",
            "iteration 1200 / 2500: loss 375.659570\n",
            "iteration 1300 / 2500: loss 333.635453\n",
            "iteration 1400 / 2500: loss 295.928851\n",
            "iteration 1500 / 2500: loss 262.768165\n",
            "iteration 1600 / 2500: loss 233.748849\n",
            "iteration 1700 / 2500: loss 207.566668\n",
            "iteration 1800 / 2500: loss 184.136400\n",
            "iteration 1900 / 2500: loss 163.539104\n",
            "iteration 2000 / 2500: loss 145.540977\n",
            "iteration 2100 / 2500: loss 130.065260\n",
            "iteration 2200 / 2500: loss 115.349317\n",
            "iteration 2300 / 2500: loss 102.502685\n",
            "iteration 2400 / 2500: loss 91.440053\n",
            "iteration 0 / 2500: loss 5242.436063\n",
            "iteration 100 / 2500: loss 3513.786793\n",
            "iteration 200 / 2500: loss 2353.739484\n",
            "iteration 300 / 2500: loss 1578.348601\n",
            "iteration 400 / 2500: loss 1058.414217\n",
            "iteration 500 / 2500: loss 710.162209\n",
            "iteration 600 / 2500: loss 477.127606\n",
            "iteration 700 / 2500: loss 320.791895\n",
            "iteration 800 / 2500: loss 216.118471\n",
            "iteration 900 / 2500: loss 145.725367\n",
            "iteration 1000 / 2500: loss 98.892450\n",
            "iteration 1100 / 2500: loss 67.421110\n",
            "iteration 1200 / 2500: loss 46.669108\n",
            "iteration 1300 / 2500: loss 31.970575\n",
            "iteration 1400 / 2500: loss 22.892322\n",
            "iteration 1500 / 2500: loss 16.893918\n",
            "iteration 1600 / 2500: loss 12.443116\n",
            "iteration 1700 / 2500: loss 9.633396\n",
            "iteration 1800 / 2500: loss 7.851147\n",
            "iteration 1900 / 2500: loss 6.671891\n",
            "iteration 2000 / 2500: loss 5.394009\n",
            "iteration 2100 / 2500: loss 5.204888\n",
            "iteration 2200 / 2500: loss 4.301546\n",
            "iteration 2300 / 2500: loss 4.243281\n",
            "iteration 2400 / 2500: loss 4.106873\n",
            "iteration 0 / 2500: loss 62.520756\n",
            "iteration 100 / 2500: loss 56.020817\n",
            "iteration 200 / 2500: loss 52.763683\n",
            "iteration 300 / 2500: loss 50.731512\n",
            "iteration 400 / 2500: loss 49.127580\n",
            "iteration 500 / 2500: loss 47.099435\n",
            "iteration 600 / 2500: loss 45.066059\n",
            "iteration 700 / 2500: loss 43.765394\n",
            "iteration 800 / 2500: loss 41.612514\n",
            "iteration 900 / 2500: loss 39.734151\n",
            "iteration 1000 / 2500: loss 38.661913\n",
            "iteration 1100 / 2500: loss 37.007208\n",
            "iteration 1200 / 2500: loss 35.806279\n",
            "iteration 1300 / 2500: loss 34.814738\n",
            "iteration 1400 / 2500: loss 33.201218\n",
            "iteration 1500 / 2500: loss 32.253573\n",
            "iteration 1600 / 2500: loss 31.069504\n",
            "iteration 1700 / 2500: loss 30.101250\n",
            "iteration 1800 / 2500: loss 28.607156\n",
            "iteration 1900 / 2500: loss 27.520229\n",
            "iteration 2000 / 2500: loss 26.071746\n",
            "iteration 2100 / 2500: loss 26.066450\n",
            "iteration 2200 / 2500: loss 24.365524\n",
            "iteration 2300 / 2500: loss 24.334329\n",
            "iteration 2400 / 2500: loss 23.044047\n",
            "iteration 0 / 2500: loss 115.239842\n",
            "iteration 100 / 2500: loss 102.877720\n",
            "iteration 200 / 2500: loss 94.114412\n",
            "iteration 300 / 2500: loss 87.099681\n",
            "iteration 400 / 2500: loss 80.050177\n",
            "iteration 500 / 2500: loss 73.954201\n",
            "iteration 600 / 2500: loss 69.268352\n",
            "iteration 700 / 2500: loss 63.422909\n",
            "iteration 800 / 2500: loss 58.697321\n",
            "iteration 900 / 2500: loss 53.774349\n",
            "iteration 1000 / 2500: loss 50.310316\n",
            "iteration 1100 / 2500: loss 46.759477\n",
            "iteration 1200 / 2500: loss 42.975627\n",
            "iteration 1300 / 2500: loss 40.180563\n",
            "iteration 1400 / 2500: loss 36.873971\n",
            "iteration 1500 / 2500: loss 34.499412\n",
            "iteration 1600 / 2500: loss 32.021360\n",
            "iteration 1700 / 2500: loss 29.815262\n",
            "iteration 1800 / 2500: loss 27.391714\n",
            "iteration 1900 / 2500: loss 25.363880\n",
            "iteration 2000 / 2500: loss 24.316716\n",
            "iteration 2100 / 2500: loss 22.179545\n",
            "iteration 2200 / 2500: loss 20.996163\n",
            "iteration 2300 / 2500: loss 19.458595\n",
            "iteration 2400 / 2500: loss 17.941489\n",
            "iteration 0 / 2500: loss 172.474949\n",
            "iteration 100 / 2500: loss 144.378573\n",
            "iteration 200 / 2500: loss 127.628924\n",
            "iteration 300 / 2500: loss 113.343239\n",
            "iteration 400 / 2500: loss 100.855103\n",
            "iteration 500 / 2500: loss 89.627393\n",
            "iteration 600 / 2500: loss 79.474215\n",
            "iteration 700 / 2500: loss 71.075471\n",
            "iteration 800 / 2500: loss 62.781387\n",
            "iteration 900 / 2500: loss 56.136888\n",
            "iteration 1000 / 2500: loss 50.630622\n",
            "iteration 1100 / 2500: loss 45.340046\n",
            "iteration 1200 / 2500: loss 39.798081\n",
            "iteration 1300 / 2500: loss 35.809786\n",
            "iteration 1400 / 2500: loss 32.346280\n",
            "iteration 1500 / 2500: loss 28.553902\n",
            "iteration 1600 / 2500: loss 26.169497\n",
            "iteration 1700 / 2500: loss 23.452887\n",
            "iteration 1800 / 2500: loss 20.664223\n",
            "iteration 1900 / 2500: loss 19.110307\n",
            "iteration 2000 / 2500: loss 17.067310\n",
            "iteration 2100 / 2500: loss 15.187378\n",
            "iteration 2200 / 2500: loss 13.913921\n",
            "iteration 2300 / 2500: loss 13.105142\n",
            "iteration 2400 / 2500: loss 11.440152\n",
            "iteration 0 / 2500: loss 535.883310\n",
            "iteration 100 / 2500: loss 355.052933\n",
            "iteration 200 / 2500: loss 238.345557\n",
            "iteration 300 / 2500: loss 161.022307\n",
            "iteration 400 / 2500: loss 108.721582\n",
            "iteration 500 / 2500: loss 73.734046\n",
            "iteration 600 / 2500: loss 50.574765\n",
            "iteration 700 / 2500: loss 34.581761\n",
            "iteration 800 / 2500: loss 24.455145\n",
            "iteration 900 / 2500: loss 17.249010\n",
            "iteration 1000 / 2500: loss 12.626827\n",
            "iteration 1100 / 2500: loss 9.590437\n",
            "iteration 1200 / 2500: loss 7.849588\n",
            "iteration 1300 / 2500: loss 6.179112\n",
            "iteration 1400 / 2500: loss 5.095167\n",
            "iteration 1500 / 2500: loss 4.162665\n",
            "iteration 1600 / 2500: loss 4.211168\n",
            "iteration 1700 / 2500: loss 4.013198\n",
            "iteration 1800 / 2500: loss 3.851025\n",
            "iteration 1900 / 2500: loss 3.613109\n",
            "iteration 2000 / 2500: loss 3.591717\n",
            "iteration 2100 / 2500: loss 2.934746\n",
            "iteration 2200 / 2500: loss 3.579613\n",
            "iteration 2300 / 2500: loss 3.712828\n",
            "iteration 2400 / 2500: loss 3.667224\n",
            "iteration 0 / 2500: loss 1066.704730\n",
            "iteration 100 / 2500: loss 476.428134\n",
            "iteration 200 / 2500: loss 215.347345\n",
            "iteration 300 / 2500: loss 98.315686\n",
            "iteration 400 / 2500: loss 45.623185\n",
            "iteration 500 / 2500: loss 22.235318\n",
            "iteration 600 / 2500: loss 12.105479\n",
            "iteration 700 / 2500: loss 7.206312\n",
            "iteration 800 / 2500: loss 4.889116\n",
            "iteration 900 / 2500: loss 4.151559\n",
            "iteration 1000 / 2500: loss 4.007720\n",
            "iteration 1100 / 2500: loss 3.713518\n",
            "iteration 1200 / 2500: loss 3.708584\n",
            "iteration 1300 / 2500: loss 3.238476\n",
            "iteration 1400 / 2500: loss 3.313757\n",
            "iteration 1500 / 2500: loss 3.368316\n",
            "iteration 1600 / 2500: loss 3.480107\n",
            "iteration 1700 / 2500: loss 3.146911\n",
            "iteration 1800 / 2500: loss 3.625479\n",
            "iteration 1900 / 2500: loss 3.019251\n",
            "iteration 2000 / 2500: loss 3.288422\n",
            "iteration 2100 / 2500: loss 3.387548\n",
            "iteration 2200 / 2500: loss 3.127781\n",
            "iteration 2300 / 2500: loss 3.398200\n",
            "iteration 2400 / 2500: loss 3.047436\n",
            "iteration 0 / 2500: loss 1588.454462\n",
            "iteration 100 / 2500: loss 475.683107\n",
            "iteration 200 / 2500: loss 144.694327\n",
            "iteration 300 / 2500: loss 45.856563\n",
            "iteration 400 / 2500: loss 15.886985\n",
            "iteration 500 / 2500: loss 7.825574\n",
            "iteration 600 / 2500: loss 4.495164\n",
            "iteration 700 / 2500: loss 4.242228\n",
            "iteration 800 / 2500: loss 3.336983\n",
            "iteration 900 / 2500: loss 3.414955\n",
            "iteration 1000 / 2500: loss 3.461008\n",
            "iteration 1100 / 2500: loss 3.736705\n",
            "iteration 1200 / 2500: loss 3.560944\n",
            "iteration 1300 / 2500: loss 3.793317\n",
            "iteration 1400 / 2500: loss 3.659678\n",
            "iteration 1500 / 2500: loss 3.174447\n",
            "iteration 1600 / 2500: loss 3.763137\n",
            "iteration 1700 / 2500: loss 3.067813\n",
            "iteration 1800 / 2500: loss 3.274463\n",
            "iteration 1900 / 2500: loss 3.535215\n",
            "iteration 2000 / 2500: loss 3.201205\n",
            "iteration 2100 / 2500: loss 3.370225\n",
            "iteration 2200 / 2500: loss 3.590419\n",
            "iteration 2300 / 2500: loss 3.590146\n",
            "iteration 2400 / 2500: loss 3.003426\n",
            "iteration 0 / 2500: loss 5295.076161\n",
            "iteration 100 / 2500: loss 96.766574\n",
            "iteration 200 / 2500: loss 5.586601\n",
            "iteration 300 / 2500: loss 3.868857\n",
            "iteration 400 / 2500: loss 4.292930\n",
            "iteration 500 / 2500: loss 4.006181\n",
            "iteration 600 / 2500: loss 3.939755\n",
            "iteration 700 / 2500: loss 4.137964\n",
            "iteration 800 / 2500: loss 3.629147\n",
            "iteration 900 / 2500: loss 4.148947\n",
            "iteration 1000 / 2500: loss 4.157725\n",
            "iteration 1100 / 2500: loss 4.253350\n",
            "iteration 1200 / 2500: loss 3.930022\n",
            "iteration 1300 / 2500: loss 4.039658\n",
            "iteration 1400 / 2500: loss 3.869950\n",
            "iteration 1500 / 2500: loss 3.800419\n",
            "iteration 1600 / 2500: loss 3.730731\n",
            "iteration 1700 / 2500: loss 3.956197\n",
            "iteration 1800 / 2500: loss 3.866395\n",
            "iteration 1900 / 2500: loss 3.434337\n",
            "iteration 2000 / 2500: loss 3.871586\n",
            "iteration 2100 / 2500: loss 4.097596\n",
            "iteration 2200 / 2500: loss 3.769586\n",
            "iteration 2300 / 2500: loss 3.701291\n",
            "iteration 2400 / 2500: loss 3.927463\n",
            "iteration 0 / 2500: loss 64.569697\n",
            "iteration 100 / 2500: loss 38.731194\n",
            "iteration 200 / 2500: loss 26.513802\n",
            "iteration 300 / 2500: loss 19.559173\n",
            "iteration 400 / 2500: loss 13.229354\n",
            "iteration 500 / 2500: loss 9.658361\n",
            "iteration 600 / 2500: loss 7.829898\n",
            "iteration 700 / 2500: loss 6.243382\n",
            "iteration 800 / 2500: loss 4.607532\n",
            "iteration 900 / 2500: loss 4.322791\n",
            "iteration 1000 / 2500: loss 4.210160\n",
            "iteration 1100 / 2500: loss 3.961191\n",
            "iteration 1200 / 2500: loss 3.823169\n",
            "iteration 1300 / 2500: loss 3.491687\n",
            "iteration 1400 / 2500: loss 3.110075\n",
            "iteration 1500 / 2500: loss 3.504811\n",
            "iteration 1600 / 2500: loss 3.583069\n",
            "iteration 1700 / 2500: loss 3.170849\n",
            "iteration 1800 / 2500: loss 2.954038\n",
            "iteration 1900 / 2500: loss 3.418880\n",
            "iteration 2000 / 2500: loss 2.905012\n",
            "iteration 2100 / 2500: loss 3.161864\n",
            "iteration 2200 / 2500: loss 3.302072\n",
            "iteration 2300 / 2500: loss 2.846881\n",
            "iteration 2400 / 2500: loss 2.832511\n",
            "iteration 0 / 2500: loss 121.397074\n",
            "iteration 100 / 2500: loss 50.484774\n",
            "iteration 200 / 2500: loss 23.843198\n",
            "iteration 300 / 2500: loss 12.574686\n",
            "iteration 400 / 2500: loss 7.861707\n",
            "iteration 500 / 2500: loss 4.547423\n",
            "iteration 600 / 2500: loss 3.348309\n",
            "iteration 700 / 2500: loss 3.547806\n",
            "iteration 800 / 2500: loss 3.809739\n",
            "iteration 900 / 2500: loss 3.126118\n",
            "iteration 1000 / 2500: loss 2.829775\n",
            "iteration 1100 / 2500: loss 3.410367\n",
            "iteration 1200 / 2500: loss 3.088932\n",
            "iteration 1300 / 2500: loss 3.624687\n",
            "iteration 1400 / 2500: loss 3.552234\n",
            "iteration 1500 / 2500: loss 3.083468\n",
            "iteration 1600 / 2500: loss 4.460195\n",
            "iteration 1700 / 2500: loss 2.948151\n",
            "iteration 1800 / 2500: loss 3.629790\n",
            "iteration 1900 / 2500: loss 3.849994\n",
            "iteration 2000 / 2500: loss 3.332937\n",
            "iteration 2100 / 2500: loss 3.072280\n",
            "iteration 2200 / 2500: loss 2.693729\n",
            "iteration 2300 / 2500: loss 3.267622\n",
            "iteration 2400 / 2500: loss 3.369131\n",
            "iteration 0 / 2500: loss 169.496076\n",
            "iteration 100 / 2500: loss 50.225745\n",
            "iteration 200 / 2500: loss 17.357392\n",
            "iteration 300 / 2500: loss 7.655484\n",
            "iteration 400 / 2500: loss 4.569043\n",
            "iteration 500 / 2500: loss 3.823591\n",
            "iteration 600 / 2500: loss 3.815732\n",
            "iteration 700 / 2500: loss 3.338204\n",
            "iteration 800 / 2500: loss 2.954944\n",
            "iteration 900 / 2500: loss 4.066639\n",
            "iteration 1000 / 2500: loss 3.798690\n",
            "iteration 1100 / 2500: loss 3.641457\n",
            "iteration 1200 / 2500: loss 3.381287\n",
            "iteration 1300 / 2500: loss 3.964380\n",
            "iteration 1400 / 2500: loss 3.496325\n",
            "iteration 1500 / 2500: loss 3.664700\n",
            "iteration 1600 / 2500: loss 3.512542\n",
            "iteration 1700 / 2500: loss 3.856228\n",
            "iteration 1800 / 2500: loss 3.635333\n",
            "iteration 1900 / 2500: loss 3.567238\n",
            "iteration 2000 / 2500: loss 3.094247\n",
            "iteration 2100 / 2500: loss 3.658914\n",
            "iteration 2200 / 2500: loss 3.636432\n",
            "iteration 2300 / 2500: loss 3.236728\n",
            "iteration 2400 / 2500: loss 3.435288\n",
            "iteration 0 / 2500: loss 538.615083\n",
            "iteration 100 / 2500: loss 13.059774\n",
            "iteration 200 / 2500: loss 4.150729\n",
            "iteration 300 / 2500: loss 3.646064\n",
            "iteration 400 / 2500: loss 4.042897\n",
            "iteration 500 / 2500: loss 4.174282\n",
            "iteration 600 / 2500: loss 4.450900\n",
            "iteration 700 / 2500: loss 4.041306\n",
            "iteration 800 / 2500: loss 4.262003\n",
            "iteration 900 / 2500: loss 3.779147\n",
            "iteration 1000 / 2500: loss 4.441731\n",
            "iteration 1100 / 2500: loss 3.829957\n",
            "iteration 1200 / 2500: loss 3.639063\n",
            "iteration 1300 / 2500: loss 3.645388\n",
            "iteration 1400 / 2500: loss 4.315600\n",
            "iteration 1500 / 2500: loss 3.548786\n",
            "iteration 1600 / 2500: loss 3.439838\n",
            "iteration 1700 / 2500: loss 4.270153\n",
            "iteration 1800 / 2500: loss 4.001025\n",
            "iteration 1900 / 2500: loss 4.218641\n",
            "iteration 2000 / 2500: loss 4.613836\n",
            "iteration 2100 / 2500: loss 3.872103\n",
            "iteration 2200 / 2500: loss 3.685277\n",
            "iteration 2300 / 2500: loss 4.315047\n",
            "iteration 2400 / 2500: loss 3.533165\n",
            "iteration 0 / 2500: loss 1065.833508\n",
            "iteration 100 / 2500: loss 4.414508\n",
            "iteration 200 / 2500: loss 4.473223\n",
            "iteration 300 / 2500: loss 3.979772\n",
            "iteration 400 / 2500: loss 4.144233\n",
            "iteration 500 / 2500: loss 4.264095\n",
            "iteration 600 / 2500: loss 3.668531\n",
            "iteration 700 / 2500: loss 3.549575\n",
            "iteration 800 / 2500: loss 5.805619\n",
            "iteration 900 / 2500: loss 4.606390\n",
            "iteration 1000 / 2500: loss 3.984180\n",
            "iteration 1100 / 2500: loss 4.393119\n",
            "iteration 1200 / 2500: loss 4.029941\n",
            "iteration 1300 / 2500: loss 3.859243\n",
            "iteration 1400 / 2500: loss 4.195465\n",
            "iteration 1500 / 2500: loss 4.364733\n",
            "iteration 1600 / 2500: loss 4.115492\n",
            "iteration 1700 / 2500: loss 4.424651\n",
            "iteration 1800 / 2500: loss 3.672852\n",
            "iteration 1900 / 2500: loss 4.375098\n",
            "iteration 2000 / 2500: loss 3.864615\n",
            "iteration 2100 / 2500: loss 3.971236\n",
            "iteration 2200 / 2500: loss 4.495996\n",
            "iteration 2300 / 2500: loss 3.367419\n",
            "iteration 2400 / 2500: loss 5.273928\n",
            "iteration 0 / 2500: loss 1597.097558\n",
            "iteration 100 / 2500: loss 4.177333\n",
            "iteration 200 / 2500: loss 3.988093\n",
            "iteration 300 / 2500: loss 4.571837\n",
            "iteration 400 / 2500: loss 4.273151\n",
            "iteration 500 / 2500: loss 4.055714\n",
            "iteration 600 / 2500: loss 4.702672\n",
            "iteration 700 / 2500: loss 3.931688\n",
            "iteration 800 / 2500: loss 3.887715\n",
            "iteration 900 / 2500: loss 4.419814\n",
            "iteration 1000 / 2500: loss 3.865279\n",
            "iteration 1100 / 2500: loss 4.558752\n",
            "iteration 1200 / 2500: loss 4.047220\n",
            "iteration 1300 / 2500: loss 4.168286\n",
            "iteration 1400 / 2500: loss 4.593066\n",
            "iteration 1500 / 2500: loss 3.750575\n",
            "iteration 1600 / 2500: loss 4.809848\n",
            "iteration 1700 / 2500: loss 4.018513\n",
            "iteration 1800 / 2500: loss 4.068377\n",
            "iteration 1900 / 2500: loss 4.714855\n",
            "iteration 2000 / 2500: loss 3.862874\n",
            "iteration 2100 / 2500: loss 3.836229\n",
            "iteration 2200 / 2500: loss 3.841136\n",
            "iteration 2300 / 2500: loss 5.479385\n",
            "iteration 2400 / 2500: loss 4.611637\n",
            "iteration 0 / 2500: loss 5254.337814\n",
            "iteration 100 / 2500: loss 5.909410\n",
            "iteration 200 / 2500: loss 6.110029\n",
            "iteration 300 / 2500: loss 4.532345\n",
            "iteration 400 / 2500: loss 5.255539\n",
            "iteration 500 / 2500: loss 6.016017\n",
            "iteration 600 / 2500: loss 5.608014\n",
            "iteration 700 / 2500: loss 4.767581\n",
            "iteration 800 / 2500: loss 5.400708\n",
            "iteration 900 / 2500: loss 4.891099\n",
            "iteration 1000 / 2500: loss 4.271854\n",
            "iteration 1100 / 2500: loss 5.724099\n",
            "iteration 1200 / 2500: loss 5.353084\n",
            "iteration 1300 / 2500: loss 4.568938\n",
            "iteration 1400 / 2500: loss 5.557086\n",
            "iteration 1500 / 2500: loss 5.358366\n",
            "iteration 1600 / 2500: loss 5.521589\n",
            "iteration 1700 / 2500: loss 5.330071\n",
            "iteration 1800 / 2500: loss 5.649568\n",
            "iteration 1900 / 2500: loss 5.127742\n",
            "iteration 2000 / 2500: loss 4.993581\n",
            "iteration 2100 / 2500: loss 5.100398\n",
            "iteration 2200 / 2500: loss 5.576757\n",
            "iteration 2300 / 2500: loss 6.714563\n",
            "iteration 2400 / 2500: loss 4.243339\n",
            "lr 1.000000e-08 reg 1.000000e+03 train accuracy: 0.382150 val accuracy: 0.388978\n",
            "lr 1.000000e-08 reg 2.000000e+03 train accuracy: 0.380350 val accuracy: 0.376997\n",
            "lr 1.000000e-08 reg 3.000000e+03 train accuracy: 0.371200 val accuracy: 0.384984\n",
            "lr 1.000000e-08 reg 1.000000e+04 train accuracy: 0.406050 val accuracy: 0.392971\n",
            "lr 1.000000e-08 reg 2.000000e+04 train accuracy: 0.442200 val accuracy: 0.437700\n",
            "lr 1.000000e-08 reg 3.000000e+04 train accuracy: 0.465800 val accuracy: 0.468051\n",
            "lr 1.000000e-08 reg 1.000000e+05 train accuracy: 0.475250 val accuracy: 0.484824\n",
            "lr 1.000000e-07 reg 1.000000e+03 train accuracy: 0.485950 val accuracy: 0.480831\n",
            "lr 1.000000e-07 reg 2.000000e+03 train accuracy: 0.507950 val accuracy: 0.481629\n",
            "lr 1.000000e-07 reg 3.000000e+03 train accuracy: 0.520800 val accuracy: 0.514377\n",
            "lr 1.000000e-07 reg 1.000000e+04 train accuracy: 0.514450 val accuracy: 0.504792\n",
            "lr 1.000000e-07 reg 2.000000e+04 train accuracy: 0.492100 val accuracy: 0.488019\n",
            "lr 1.000000e-07 reg 3.000000e+04 train accuracy: 0.493250 val accuracy: 0.496805\n",
            "lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.474950 val accuracy: 0.484026\n",
            "lr 1.000000e-06 reg 1.000000e+03 train accuracy: 0.530100 val accuracy: 0.515176\n",
            "lr 1.000000e-06 reg 2.000000e+03 train accuracy: 0.525450 val accuracy: 0.523163\n",
            "lr 1.000000e-06 reg 3.000000e+03 train accuracy: 0.497500 val accuracy: 0.480831\n",
            "lr 1.000000e-06 reg 1.000000e+04 train accuracy: 0.494000 val accuracy: 0.490415\n",
            "lr 1.000000e-06 reg 2.000000e+04 train accuracy: 0.430350 val accuracy: 0.400160\n",
            "lr 1.000000e-06 reg 3.000000e+04 train accuracy: 0.463050 val accuracy: 0.460064\n",
            "lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.416050 val accuracy: 0.426518\n",
            "best validation accuracy achieved during cross-validation: 0.523163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnVPLM1Fj5P2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "0633ba13-f44e-47bc-fdff-e1c9c7bb4ff0"
      },
      "source": [
        "# Visualize the cross-validation results\n",
        "import math\n",
        "x_scatter = [math.log10(x[0]) for x in results]\n",
        "y_scatter = [math.log10(x[1]) for x in results]\n",
        "\n",
        "# plot training accuracy\n",
        "marker_size = 100\n",
        "colors = [results[x][0] for x in results]\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.scatter(x_scatter, y_scatter, marker_size, c=colors)\n",
        "plt.colorbar()\n",
        "plt.xlabel('log learning rate')\n",
        "plt.ylabel('log regularization strength')\n",
        "plt.title('CIFAR-10 training accuracy')\n",
        "\n",
        "# plot validation accuracy\n",
        "colors = [results[x][1] for x in results] # default size of markers is 20\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.scatter(x_scatter, y_scatter, marker_size, c=colors)\n",
        "plt.colorbar()\n",
        "plt.xlabel('log learning rate')\n",
        "plt.ylabel('log regularization strength')\n",
        "plt.title('CIFAR-10 validation accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhTjjnkoj5Ss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64fa7965-28ef-4555-bc08-cf678f9a634c"
      },
      "source": [
        "# Evaluate the best svm on test set\n",
        "y_test_pred = best_svm.predict(X_test)\n",
        "test_accuracy = np.mean(y_test == y_test_pred)\n",
        "print('linear SVM on raw pixels final test set accuracy: %f' % test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear SVM on raw pixels final test set accuracy: 0.514022\n"
          ]
        }
      ]
    }
  ]
}